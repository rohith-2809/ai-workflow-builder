<img width="1919" height="924" alt="image" src="https://github.com/user-attachments/assets/b9f65ed4-24eb-4e10-94c2-1b26b1721662" /># Advanced AI Workflow Builder: A Full-Stack No-Code Platform

This repository contains the complete source code for the **No-Code AI Workflow Builder**, a full-stack application designed to empower users to create intelligent AI-driven workflows without writing code. The platform allows users to build and run complex AI pipelines by visually connecting modular components, such as document processors, large language models, and web search utilities.

The application supports use cases like document-based question answering (RAG), live data retrieval via web search, and natural language response generation, with all interactions happening through an intuitive graphical interface.

________________________________________________________________________________________________________________________________________________________________


<img width="1919" height="924" alt="image" src="https://github.com/user-attachments/assets/89f3a7bf-6aa5-4710-81d4-86b30005850a" />


________________________________________________________________________________________________________________________________________________________________


## Key Features

### Visual Workflow Canvas
An interactive visual builder developed using React Flow. Users can drag-and-drop different nodes (components), connect them, and configure them to form an execution flow.

### Modular AI Components
- **User Query**: Accepts natural language input.
- **Knowledge Base**: Supports uploading of PDF documents. The backend parses the documents and stores them as vector embeddings for retrieval.
- **LLM Engine**: Processes input using Google Gemini for text generation. Optionally enhanced with real-time Google search using SerpAPI.
- **Output Node**: Displays streamed responses generated by the workflow.

### Document-Aware AI (RAG)
PDF files uploaded to the Knowledge Base are processed using PyMuPDF. Text content is extracted, embedded using a sentence transformer, and stored in a local ChromaDB instance for fast semantic retrieval.

### Live Web Search Integration
When enabled, the LLM Engine component utilizes SerpAPI to perform live Google searches, giving the AI access to current, web-based information.

### Dynamic Configuration Panel
Each node on the canvas exposes customizable parameters in a contextual sidebar, enabling flexible, per-component behavior configuration.

### Streaming Chat Output
The final result of a workflow execution is streamed from the backend in real time using Server-Sent Events (SSE), offering a fluid, interactive user experience.

### Workflow Validation
A "Build Stack" button checks that all required connections between nodes are valid and complete before the workflow can be executed, reducing runtime errors.

### User-Friendly Interface
- Back button allows switching between configuration and chat views.
- Users can delete connections directly from the canvas.
- Errors are reported with visual cues and toast notifications.

________________________________________________________________________________________________________________________________________________________________


## Technologies and Components Used

| Function               | Technology / Library                      |
|------------------------|-------------------------------------------|
| Frontend Framework     | React.js                                  |
| UI Styling             | Tailwind CSS                              |
| Canvas Interaction     | React Flow                                |
| State Management       | React Context                             |
| Notifications          | react-toastify                            |
| Backend API            | FastAPI                                   |
| Embedding Model        | all-MiniLM-L6-v2 (via ChromaDB)           |
| Vector Database        | ChromaDB (local, persistent mode)         |
| Language Model         | Gemini 1.5 Flash (Google Generative AI)   |
| Web Search Integration | SerpAPI (via google-search-results)       |
| PDF Parsing            | PyMuPDF                                    |
| Streaming Responses    | Server-Sent Events (SSE-Starlette)        |

________________________________________________________________________________________________________________________________________________________________


## Project Journey and Solutions to Key Challenges

### 1. Backend ImportError at Startup
**Problem**: FastAPI server crashed with `ImportError: cannot import name 'GoogleSearch' from 'serpapi'`.

**Root Cause**: Incorrect library installed. The intended functionality required `google-search-results`, but `serpapi` was mistakenly installed.

**Solution**:
- Created a virtual environment to isolate dependencies.
- Corrected `requirements.txt` to include `google-search-results`.
- Removed the old `serpapi` package.
- Cleanly reinstalled dependencies and used `uvicorn` to start the server.

________________________________________________________________________________________________________________________________________________________________


### 2. Silent Failures in File Upload
**Problem**: The file upload component did not trigger a network request, with no visible frontend errors.

**Diagnosis**: JavaScript handler function was not properly triggering the `fetch` call due to incorrect FormData handling.

**Solution**:
- Used `console.log()` statements to trace function execution.
- Rewrote the `handleFileChange` function to properly create and submit the FormData payload.
- Ensured the correct MIME type and API endpoint usage.

________________________________________________________________________________________________________________________________________________________________

### 3. Garbled or Repeating Chat Responses
**Problem**: The frontend chat displayed malformed or repeating responses.

**Root Causes**:
- The frontend attempted to parse Server-Sent Events (SSE) as plain text.
- React Strict Mode caused components to render twice, sending duplicate requests.

**Solution**:
- Replaced FastAPI’s `EventSourceResponse` with `StreamingResponse` configured with `text/event-stream` as the media type.
- Refactored the frontend API call to use `useEffect` and `AbortController` for proper cleanup, preventing multiple fetches.

---
________________________________________________________________________________________________________________________________________________________________

## Running the Application

### Method 1: Clone from GitHub

1. **Clone the Repository**
```bash
git clone https://github.com/your-username/ai-workflow-builder.git
cd ai-workflow-builder
________________________________________________________________________________________________________________________________________________________________
2. **Set Up Backend**
cd backend
python -m venv venv
.\venv\Scripts\Activate.ps1      # For Windows PowerShell
# OR
source venv/bin/activate         # For macOS/Linux
pip install -r requirements.txt
# Add your API keys to a .env file

________________________________________________________________________________________________________________________________________________________________
3. **Set Up Frontend**

cd ..
npm install
Run the Application

Open two terminals:
________________________________________________________________________________________________________________________________________________________________

Terminal 1: Start Backend

bash
Copy
Edit
cd backend
uvicorn main:app --reload
Backend will be live at http://localhost:8000.
________________________________________________________________________________________________________________________________________________________________

Terminal 2: Start Frontend

bash
Copy
Edit
cd ..
npm run dev
Frontend will be live at http://localhost:5173.

Method 2: Run from Downloaded ZIP (e.g., Google Drive)
Download and extract the ZIP file.

Open the extracted folder in a code editor.

Follow the same backend and frontend setup steps as above:

Create .env

Create virtual environment and install dependencies

Run both frontend and backend
________________________________________________________________________________________________________________________________________________________________

Folder Structure
css
Copy
Edit
ai-workflow-builder/
│
├── backend/
│   ├── main.py
│   ├── utils/
│   ├── chroma_db/
│   ├── requirements.txt
│   └── .env
│
├── frontend/
│   ├── src/
│   │   ├── components/
│   │   ├── context/
│   │   ├── hooks/
│   │   └── App.jsx
│   ├── public/
│   └── package.json
│
└── README.md
---
